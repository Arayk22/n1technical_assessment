[["index.html", "N1 Technical Assessment 1 Assessment Objective", " N1 Technical Assessment Austin Kolvek 2025-01-23 1 Assessment Objective The goal of this assessment is to take the data N1 Health has provided to assess where they should deploy a food access program. "],["eda.html", "2 EDA", " 2 EDA Lets bring in the data to get a sense for what we are working with. import sqlite3 import pandas as pd import seaborn as sns import matplotlib.pyplot as plt import numpy as np #Path to the database db_path = r&quot;C:\\Users\\austi\\OneDrive\\Documents\\Interviews\\N1\\Technical Assessment\\challenge.db&quot; connection = sqlite3.connect(db_path) query = &quot;select * from access&quot; data = pd.read_sql_query(query,connection) connection.close() I am going to look through the data and get an understanding for how it is structured and what analysis can be performed. print(data.info()) ## &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; ## RangeIndex: 3143 entries, 0 to 3142 ## Data columns (total 45 columns): ## # Column Non-Null Count Dtype ## --- ------ -------------- ----- ## 0 index 3143 non-null int64 ## 1 FIPS 3143 non-null int64 ## 2 State 3143 non-null object ## 3 County 3143 non-null object ## 4 LACCESS_POP10 3143 non-null float64 ## 5 LACCESS_POP15 3124 non-null float64 ## 6 PCH_LACCESS_POP_10_15 3117 non-null float64 ## 7 PCT_LACCESS_POP10 3143 non-null float64 ## 8 PCT_LACCESS_POP15 3124 non-null float64 ## 9 LACCESS_LOWI10 3143 non-null float64 ## 10 LACCESS_LOWI15 3123 non-null float64 ## 11 PCH_LACCESS_LOWI_10_15 3115 non-null float64 ## 12 PCT_LACCESS_LOWI10 3143 non-null float64 ## 13 PCT_LACCESS_LOWI15 3123 non-null float64 ## 14 LACCESS_HHNV10 3143 non-null float64 ## 15 LACCESS_HHNV15 3140 non-null float64 ## 16 PCH_LACCESS_HHNV_10_15 3129 non-null float64 ## 17 PCT_LACCESS_HHNV10 3143 non-null float64 ## 18 PCT_LACCESS_HHNV15 3140 non-null float64 ## 19 LACCESS_SNAP15 3123 non-null float64 ## 20 PCT_LACCESS_SNAP15 3123 non-null float64 ## 21 LACCESS_CHILD10 3143 non-null float64 ## 22 LACCESS_CHILD15 3124 non-null float64 ## 23 LACCESS_CHILD_10_15 3115 non-null float64 ## 24 PCT_LACCESS_CHILD10 3143 non-null float64 ## 25 PCT_LACCESS_CHILD15 3124 non-null float64 ## 26 LACCESS_SENIORS10 3143 non-null float64 ## 27 LACCESS_SENIORS15 3124 non-null float64 ## 28 PCH_LACCESS_SENIORS_10_15 3117 non-null float64 ## 29 PCT_LACCESS_SENIORS10 3143 non-null float64 ## 30 PCT_LACCESS_SENIORS15 3124 non-null float64 ## 31 LACCESS_WHITE15 3124 non-null float64 ## 32 PCT_LACCESS_WHITE15 3124 non-null float64 ## 33 LACCESS_BLACK15 3124 non-null float64 ## 34 PCT_LACCESS_BLACK15 3124 non-null float64 ## 35 LACCESS_HISP15 3124 non-null float64 ## 36 PCT_LACCESS_HISP15 3124 non-null float64 ## 37 LACCESS_NHASIAN15 3124 non-null float64 ## 38 PCT_LACCESS_NHASIAN15 3124 non-null float64 ## 39 LACCESS_NHNA15 3124 non-null float64 ## 40 PCT_LACCESS_NHNA15 3124 non-null float64 ## 41 LACCESS_NHPI15 3124 non-null float64 ## 42 PCT_LACCESS_NHPI15 3124 non-null float64 ## 43 LACCESS_MULTIR15 3124 non-null float64 ## 44 PCT_LACCESS_MULTIR15 3124 non-null float64 ## dtypes: float64(41), int64(2), object(2) ## memory usage: 1.1+ MB ## None There seems to be two types of variables, raw count and percentages. I am going to drop out raw counts because we are going to want to see how percentages of populations vary across the US. This will put all of the counties onto the same playing field. The other thing I have noticed is there seems to be data from 2010, 2015, and a relative difference between the two years. Where I can, I am going to drop out the single 2010 and 2015 years because I am more interested in the relative change. This will give me a sense for how that specific area has changed over time. #Change the LACCESS_CHILD_10_15 variable to keep up with the other names data.rename(columns={&#39;LACCESS_CHILD_10_15&#39;: &#39;PCH_LACCESS_CHILD_10_15&#39;}, inplace=True) data = data.loc[:, ~data.columns.str.startswith(&quot;LACCESS&quot;)] vars_drop = list ([&#39;index&#39;,&#39;PCT_LACCESS_POP10&#39;,&#39;PCT_LACCESS_POP15&#39;,&#39;PCT_LACCESS_LOWI10&#39;, &#39;PCT_LACCESS_LOWI15&#39;,&#39;PCT_LACCESS_HHNV10&#39;,&#39;PCT_LACCESS_HHNV15&#39;, &#39;PCT_LACCESS_CHILD10&#39;,&#39;PCT_LACCESS_CHILD15&#39;,&#39;PCT_LACCESS_SENIORS10&#39;, &#39;PCT_LACCESS_SENIORS15&#39;]) data.drop(columns=vars_drop, inplace=True) print(data.info()) ## &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; ## RangeIndex: 3143 entries, 0 to 3142 ## Data columns (total 16 columns): ## # Column Non-Null Count Dtype ## --- ------ -------------- ----- ## 0 FIPS 3143 non-null int64 ## 1 State 3143 non-null object ## 2 County 3143 non-null object ## 3 PCH_LACCESS_POP_10_15 3117 non-null float64 ## 4 PCH_LACCESS_LOWI_10_15 3115 non-null float64 ## 5 PCH_LACCESS_HHNV_10_15 3129 non-null float64 ## 6 PCT_LACCESS_SNAP15 3123 non-null float64 ## 7 PCH_LACCESS_CHILD_10_15 3115 non-null float64 ## 8 PCH_LACCESS_SENIORS_10_15 3117 non-null float64 ## 9 PCT_LACCESS_WHITE15 3124 non-null float64 ## 10 PCT_LACCESS_BLACK15 3124 non-null float64 ## 11 PCT_LACCESS_HISP15 3124 non-null float64 ## 12 PCT_LACCESS_NHASIAN15 3124 non-null float64 ## 13 PCT_LACCESS_NHNA15 3124 non-null float64 ## 14 PCT_LACCESS_NHPI15 3124 non-null float64 ## 15 PCT_LACCESS_MULTIR15 3124 non-null float64 ## dtypes: float64(13), int64(1), object(2) ## memory usage: 393.0+ KB ## None I am going to look to see if we have any missing values # Check for missing values in each column missing_values = data.isnull().sum() # Display columns with missing values print(missing_values) ## FIPS 0 ## State 0 ## County 0 ## PCH_LACCESS_POP_10_15 26 ## PCH_LACCESS_LOWI_10_15 28 ## PCH_LACCESS_HHNV_10_15 14 ## PCT_LACCESS_SNAP15 20 ## PCH_LACCESS_CHILD_10_15 28 ## PCH_LACCESS_SENIORS_10_15 26 ## PCT_LACCESS_WHITE15 19 ## PCT_LACCESS_BLACK15 19 ## PCT_LACCESS_HISP15 19 ## PCT_LACCESS_NHASIAN15 19 ## PCT_LACCESS_NHNA15 19 ## PCT_LACCESS_NHPI15 19 ## PCT_LACCESS_MULTIR15 19 ## dtype: int64 To fill the missing values, I am going to use MICE as the imputation method and create a binary flag that will signal to us if that observation for a specific column has been imputed or not. MICE is a statistical method used to fill missing values. Its goal is to use other variables as predictors in a regression model in the observation to predict what the missing value would be. It is important to note that all the ethnic categories all have 19 missing values. After some digging, it turns out that there are 19 counties that are missing this data. from sklearn.experimental import enable_iterative_imputer from sklearn.impute import IterativeImputer # Apply MICE imputation to numeric data imputer = IterativeImputer(max_iter=10, random_state=22) numeric_data = data.select_dtypes(include=[&#39;float64&#39;]) # Create a Data frame to store flags for imputed values flags = numeric_data.isnull().astype(int) # 1 for missing, 0 for not missing flags = flags.add_suffix(&quot;_imputed&quot;) # Append &quot;_imputed&quot; to column names # Perform imputation data_imputed = imputer.fit_transform(numeric_data) # Convert the imputed data back to a DataFrame data_imputed_df = pd.DataFrame(data_imputed, columns=numeric_data.columns) # Extract non-numeric columns non_numeric_data = data.select_dtypes(exclude=[&#39;float64&#39;]) # Concatenate the imputed numeric data, flags, and non-numeric columns data = pd.concat([non_numeric_data, data_imputed_df, flags.reset_index(drop=True)], axis=1) # Check for missing values to make sure the imputation worked missing_values = data.isnull().sum() print(missing_values) ## FIPS 0 ## State 0 ## County 0 ## PCH_LACCESS_POP_10_15 0 ## PCH_LACCESS_LOWI_10_15 0 ## PCH_LACCESS_HHNV_10_15 0 ## PCT_LACCESS_SNAP15 0 ## PCH_LACCESS_CHILD_10_15 0 ## PCH_LACCESS_SENIORS_10_15 0 ## PCT_LACCESS_WHITE15 0 ## PCT_LACCESS_BLACK15 0 ## PCT_LACCESS_HISP15 0 ## PCT_LACCESS_NHASIAN15 0 ## PCT_LACCESS_NHNA15 0 ## PCT_LACCESS_NHPI15 0 ## PCT_LACCESS_MULTIR15 0 ## PCH_LACCESS_POP_10_15_imputed 0 ## PCH_LACCESS_LOWI_10_15_imputed 0 ## PCH_LACCESS_HHNV_10_15_imputed 0 ## PCT_LACCESS_SNAP15_imputed 0 ## PCH_LACCESS_CHILD_10_15_imputed 0 ## PCH_LACCESS_SENIORS_10_15_imputed 0 ## PCT_LACCESS_WHITE15_imputed 0 ## PCT_LACCESS_BLACK15_imputed 0 ## PCT_LACCESS_HISP15_imputed 0 ## PCT_LACCESS_NHASIAN15_imputed 0 ## PCT_LACCESS_NHNA15_imputed 0 ## PCT_LACCESS_NHPI15_imputed 0 ## PCT_LACCESS_MULTIR15_imputed 0 ## dtype: int64 I am now left with 13 variables and their imputation flags that will be able to give me an idea on how a county is looking with their population having low access to stores. Next, I am going to run a correlation analysis to get an idea of any relationships with these variables # Select only numeric columns for correlation analysis numeric_data = data.select_dtypes(include=[&#39;float64&#39;, &#39;int64&#39;]) #Create the correlation Matrix correlation_matrix = numeric_data.corr() # Filter strong correlations strong_correlations = correlation_matrix.stack() # Filter only values with absolute correlation &gt;= 0.7 and exclude 1 (self-correlation) strong_correlations = strong_correlations[(np.abs(strong_correlations) &gt;= 0.7) &amp; (strong_correlations != 1)] # Remove duplicates (pairs like (A, B) and (B, A) are included twice) strong_correlations = strong_correlations[strong_correlations.index.get_level_values(0) &lt; strong_correlations.index.get_level_values(1)] # Print the strong correlations print(&quot;Strong correlations (&gt;= 0.7):&quot;) ## Strong correlations (&gt;= 0.7): print(strong_correlations) ## PCH_LACCESS_POP_10_15 PCH_LACCESS_SENIORS_10_15 0.999694 ## PCH_LACCESS_LOWI_10_15 PCH_LACCESS_POP_10_15 0.999987 ## PCH_LACCESS_SENIORS_10_15 0.999808 ## PCH_LACCESS_CHILD_10_15 PCH_LACCESS_POP_10_15 0.999961 ## PCH_LACCESS_LOWI_10_15 0.999902 ## PCH_LACCESS_SENIORS_10_15 0.999438 ## PCT_LACCESS_HISP15 PCT_LACCESS_MULTIR15 0.797906 ## PCH_LACCESS_POP_10_15_imputed PCT_LACCESS_SNAP15_imputed 0.832039 ## PCH_LACCESS_SENIORS_10_15_imputed 0.961218 ## PCT_LACCESS_WHITE15_imputed 0.853892 ## PCT_LACCESS_BLACK15_imputed 0.853892 ## PCT_LACCESS_HISP15_imputed 0.853892 ## PCT_LACCESS_NHASIAN15_imputed 0.853892 ## PCT_LACCESS_NHNA15_imputed 0.853892 ## PCT_LACCESS_NHPI15_imputed 0.853892 ## PCT_LACCESS_MULTIR15_imputed 0.853892 ## PCH_LACCESS_LOWI_10_15_imputed PCH_LACCESS_POP_10_15_imputed 0.963315 ## PCT_LACCESS_SNAP15_imputed 0.844071 ## PCH_LACCESS_SENIORS_10_15_imputed 0.925931 ## PCT_LACCESS_WHITE15_imputed 0.822567 ## PCT_LACCESS_BLACK15_imputed 0.822567 ## PCT_LACCESS_HISP15_imputed 0.822567 ## PCT_LACCESS_NHASIAN15_imputed 0.822567 ## PCT_LACCESS_NHNA15_imputed 0.822567 ## PCT_LACCESS_NHPI15_imputed 0.822567 ## PCT_LACCESS_MULTIR15_imputed 0.822567 ## PCT_LACCESS_SNAP15_imputed PCT_LACCESS_WHITE15_imputed 0.974523 ## PCH_LACCESS_CHILD_10_15_imputed PCH_LACCESS_POP_10_15_imputed 0.963315 ## PCH_LACCESS_LOWI_10_15_imputed 0.927929 ## PCT_LACCESS_SNAP15_imputed 0.801488 ## PCH_LACCESS_SENIORS_10_15_imputed 0.925931 ## PCT_LACCESS_WHITE15_imputed 0.822567 ## PCT_LACCESS_BLACK15_imputed 0.822567 ## PCT_LACCESS_HISP15_imputed 0.822567 ## PCT_LACCESS_NHASIAN15_imputed 0.822567 ## PCT_LACCESS_NHNA15_imputed 0.822567 ## PCT_LACCESS_NHPI15_imputed 0.822567 ## PCT_LACCESS_MULTIR15_imputed 0.822567 ## PCH_LACCESS_SENIORS_10_15_imputed PCT_LACCESS_SNAP15_imputed 0.832039 ## PCT_LACCESS_WHITE15_imputed 0.853892 ## PCT_LACCESS_BLACK15_imputed 0.853892 ## PCT_LACCESS_HISP15_imputed 0.853892 ## PCT_LACCESS_NHASIAN15_imputed 0.853892 ## PCT_LACCESS_NHNA15_imputed 0.853892 ## PCT_LACCESS_NHPI15_imputed 0.853892 ## PCT_LACCESS_MULTIR15_imputed 0.853892 ## PCT_LACCESS_BLACK15_imputed PCT_LACCESS_SNAP15_imputed 0.974523 ## PCT_LACCESS_HISP15_imputed PCT_LACCESS_SNAP15_imputed 0.974523 ## PCT_LACCESS_NHASIAN15_imputed PCT_LACCESS_SNAP15_imputed 0.974523 ## PCT_LACCESS_NHNA15_imputed PCT_LACCESS_SNAP15_imputed 0.974523 ## PCT_LACCESS_NHPI15_imputed PCT_LACCESS_SNAP15_imputed 0.974523 ## PCT_LACCESS_MULTIR15_imputed PCT_LACCESS_SNAP15_imputed 0.974523 ## dtype: float64 PCH_LACCESS_CHILD_10_15, PCH_LACCESS_LOWI_10_15, and PCH_LACCESS_SENIORS_10_15 are perfectly correlated with PCH_LACCESS_POP_10_15. This lets me know that I can drop out PCH_LACCESS_CHILD_10_15, PCH_LACCESS_SENIORS_10_15, and PCH_LACCESS_LOWI_10_15 due to PCH_LACCESS_POP_10_15 being able to give me the same signal. data.drop(columns=[&#39;PCH_LACCESS_CHILD_10_15&#39;,&#39;PCH_LACCESS_SENIORS_10_15&#39;, &#39;PCH_LACCESS_LOWI_10_15&#39;,&#39;PCH_LACCESS_CHILD_10_15_imputed&#39;, &#39;PCH_LACCESS_SENIORS_10_15_imputed&#39;,&#39;PCH_LACCESS_LOWI_10_15_imputed&#39;], inplace=True) print(data.info()) ## &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; ## RangeIndex: 3143 entries, 0 to 3142 ## Data columns (total 23 columns): ## # Column Non-Null Count Dtype ## --- ------ -------------- ----- ## 0 FIPS 3143 non-null int64 ## 1 State 3143 non-null object ## 2 County 3143 non-null object ## 3 PCH_LACCESS_POP_10_15 3143 non-null float64 ## 4 PCH_LACCESS_HHNV_10_15 3143 non-null float64 ## 5 PCT_LACCESS_SNAP15 3143 non-null float64 ## 6 PCT_LACCESS_WHITE15 3143 non-null float64 ## 7 PCT_LACCESS_BLACK15 3143 non-null float64 ## 8 PCT_LACCESS_HISP15 3143 non-null float64 ## 9 PCT_LACCESS_NHASIAN15 3143 non-null float64 ## 10 PCT_LACCESS_NHNA15 3143 non-null float64 ## 11 PCT_LACCESS_NHPI15 3143 non-null float64 ## 12 PCT_LACCESS_MULTIR15 3143 non-null float64 ## 13 PCH_LACCESS_POP_10_15_imputed 3143 non-null int64 ## 14 PCH_LACCESS_HHNV_10_15_imputed 3143 non-null int64 ## 15 PCT_LACCESS_SNAP15_imputed 3143 non-null int64 ## 16 PCT_LACCESS_WHITE15_imputed 3143 non-null int64 ## 17 PCT_LACCESS_BLACK15_imputed 3143 non-null int64 ## 18 PCT_LACCESS_HISP15_imputed 3143 non-null int64 ## 19 PCT_LACCESS_NHASIAN15_imputed 3143 non-null int64 ## 20 PCT_LACCESS_NHNA15_imputed 3143 non-null int64 ## 21 PCT_LACCESS_NHPI15_imputed 3143 non-null int64 ## 22 PCT_LACCESS_MULTIR15_imputed 3143 non-null int64 ## dtypes: float64(10), int64(11), object(2) ## memory usage: 564.9+ KB ## None data.to_csv(&#39;clustering_data.csv&#39;,index = False) The other interesting finding from the correlation analysis was PCT_LACCESS_HISP15 and PCT_LACCESS_MULTIR15 having a correlation of 0.8. This tells me that percentage of Hispanic ethnicity who have low access to stores and Multiracial who have low access to stores are linked together. As one of the groups increase in the percentage of people who have low access to stores, the other group goes up as well. Moving forward, I will use principal component analysis to reduce dimensionality and then perform either the k-means clustering algorithm or the DBSCAN algorithm depending on if the data is spatially grouped together or not. "],["clustering.html", "3 Clustering", " 3 Clustering Lets bring our data in for analysis. import pandas as pd import numpy as np import matplotlib.pyplot as plt data = pd.read_csv(r&quot;C:\\Project for IAA\\N1\\clustering_data.csv&quot;) numeric_data = data.select_dtypes(include=[&#39;float64&#39;]) print(numeric_data.info()) ## &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; ## RangeIndex: 3143 entries, 0 to 3142 ## Data columns (total 10 columns): ## # Column Non-Null Count Dtype ## --- ------ -------------- ----- ## 0 PCH_LACCESS_POP_10_15 3143 non-null float64 ## 1 PCH_LACCESS_HHNV_10_15 3143 non-null float64 ## 2 PCT_LACCESS_SNAP15 3143 non-null float64 ## 3 PCT_LACCESS_WHITE15 3143 non-null float64 ## 4 PCT_LACCESS_BLACK15 3143 non-null float64 ## 5 PCT_LACCESS_HISP15 3143 non-null float64 ## 6 PCT_LACCESS_NHASIAN15 3143 non-null float64 ## 7 PCT_LACCESS_NHNA15 3143 non-null float64 ## 8 PCT_LACCESS_NHPI15 3143 non-null float64 ## 9 PCT_LACCESS_MULTIR15 3143 non-null float64 ## dtypes: float64(10) ## memory usage: 245.7 KB ## None Now I am going to conduct a principal component analysis (PCA). The point of this is to reduce the number of dimensions in our data which will hopefully make it easier for a clustering algorithm to perform quicker and more accurately. from sklearn.decomposition import PCA from sklearn.preprocessing import StandardScaler import numpy as np # Standardize the numeric data scaler = StandardScaler() scaled_data = scaler.fit_transform(numeric_data) # Run PCA on the scaled data and get enough components to retain 80% of the # variance(signal) in the data pca = PCA(n_components = 0.8) principal_components = pca.fit_transform(scaled_data) pca_results = pd.DataFrame(principal_components) explained_variance_ratio = pca.explained_variance_ratio_ print(explained_variance_ratio) ## [0.2681349 0.14784806 0.13084329 0.10464956 0.10005973 0.09976022] We can use the first 6 PCA components to cluster together similar counties! Now lets look at the most important variables in each of the 6 components. # Access the loadings (coefficients) of each variable for each of the principal # components loadings = pca.components_ # Create a Data Frame for better interpretation loadings_df = pd.DataFrame(loadings, columns=numeric_data.columns) # For each component (row), identify the most important variable (highest absolute value) most_important_variables = loadings_df.abs().idxmax(axis=1) # Print the most important variable for each principal component most_important_df = pd.DataFrame({ &quot;Explained Variance Ratio&quot;: explained_variance_ratio, &quot;Most Important Variable&quot;: most_important_variables }) print(most_important_df) ## Explained Variance Ratio Most Important Variable ## 0 0.268135 PCT_LACCESS_MULTIR15 ## 1 0.147848 PCT_LACCESS_NHPI15 ## 2 0.130843 PCT_LACCESS_NHNA15 ## 3 0.104650 PCT_LACCESS_BLACK15 ## 4 0.100060 PCH_LACCESS_HHNV_10_15 ## 5 0.099760 PCH_LACCESS_POP_10_15 Here we can see which variable contributed the most to each of the 6 PCA components and the subsequent value for how much of the variance that PCA component can explain in our data. Next, I am going to look at the first two components on a graph. The idea here is to see if the data points are spatially placed on the graph. If they are, I will move forward with the DBSCAN algorithm and if they aren’t, I will move forward with the k-means algorithm. # Create a DataFrame for the first two principal components pc_df = pd.DataFrame(principal_components[:, :2], columns=[&quot;PC1&quot;, &quot;PC2&quot;]) # Scatter plot of the first two components plt.figure(figsize=(8, 6)) plt.scatter(pc_df[&quot;PC1&quot;], pc_df[&quot;PC2&quot;], alpha=0.7, edgecolor=&#39;k&#39;) # Add labels and title plt.title(&quot;Scatter Plot of the First Two Principal Components&quot;) plt.xlabel(&quot;Principal Component 1&quot;) plt.ylabel(&quot;Principal Component 2&quot;) plt.show() When looking at the graph, the data points are tightly packed together. Moving forward, I will run k-means clustering so I can group together similar counties. Before creating the k-means clusters, I am going to create an elbow plot to find the optimal number of clusters I should use. from sklearn.cluster import KMeans # Define the range of number of clusters to try cluster_range = range(1, 20) inertia_values = [] # Run K-means for each number of clusters and compute inertia for n_clusters in cluster_range: kmeans = KMeans(n_clusters=n_clusters, random_state=22) # Use the PCA results for clustering kmeans.fit(pca_results) #The inertia values are the sum of squared distances from each point to its #assigned cluster center inertia_values.append(kmeans.inertia_) #sk-container-id-1 { /* Definition of color scheme common for light and dark mode */ --sklearn-color-text: #000; --sklearn-color-text-muted: #666; --sklearn-color-line: gray; /* Definition of color scheme for unfitted estimators */ --sklearn-color-unfitted-level-0: #fff5e6; --sklearn-color-unfitted-level-1: #f6e4d2; --sklearn-color-unfitted-level-2: #ffe0b3; --sklearn-color-unfitted-level-3: chocolate; /* Definition of color scheme for fitted estimators */ --sklearn-color-fitted-level-0: #f0f8ff; --sklearn-color-fitted-level-1: #d4ebff; --sklearn-color-fitted-level-2: #b3dbfd; --sklearn-color-fitted-level-3: cornflowerblue; /* Specific color for light theme */ --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black))); --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white))); --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black))); --sklearn-color-icon: #696969; @media (prefers-color-scheme: dark) { /* Redefinition of color scheme for dark theme */ --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white))); --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111))); --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white))); --sklearn-color-icon: #878787; } } #sk-container-id-1 { color: var(--sklearn-color-text); } #sk-container-id-1 pre { padding: 0; } #sk-container-id-1 input.sk-hidden--visually { border: 0; clip: rect(1px 1px 1px 1px); clip: rect(1px, 1px, 1px, 1px); height: 1px; margin: -1px; overflow: hidden; padding: 0; position: absolute; width: 1px; } #sk-container-id-1 div.sk-dashed-wrapped { border: 1px dashed var(--sklearn-color-line); margin: 0 0.4em 0.5em 0.4em; box-sizing: border-box; padding-bottom: 0.4em; background-color: var(--sklearn-color-background); } #sk-container-id-1 div.sk-container { /* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */ display: inline-block !important; position: relative; } #sk-container-id-1 div.sk-text-repr-fallback { display: none; } div.sk-parallel-item, div.sk-serial, div.sk-item { /* draw centered vertical line to link estimators */ background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background)); background-size: 2px 100%; background-repeat: no-repeat; background-position: center center; } /* Parallel-specific style estimator block */ #sk-container-id-1 div.sk-parallel-item::after { content: \"\"; width: 100%; border-bottom: 2px solid var(--sklearn-color-text-on-default-background); flex-grow: 1; } #sk-container-id-1 div.sk-parallel { display: flex; align-items: stretch; justify-content: center; background-color: var(--sklearn-color-background); position: relative; } #sk-container-id-1 div.sk-parallel-item { display: flex; flex-direction: column; } #sk-container-id-1 div.sk-parallel-item:first-child::after { align-self: flex-end; width: 50%; } #sk-container-id-1 div.sk-parallel-item:last-child::after { align-self: flex-start; width: 50%; } #sk-container-id-1 div.sk-parallel-item:only-child::after { width: 0; } /* Serial-specific style estimator block */ #sk-container-id-1 div.sk-serial { display: flex; flex-direction: column; align-items: center; background-color: var(--sklearn-color-background); padding-right: 1em; padding-left: 1em; } /* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is clickable and can be expanded/collapsed. - Pipeline and ColumnTransformer use this feature and define the default style - Estimators will overwrite some part of the style using the `sk-estimator` class */ /* Pipeline and ColumnTransformer style (default) */ #sk-container-id-1 div.sk-toggleable { /* Default theme specific background. It is overwritten whether we have a specific estimator or a Pipeline/ColumnTransformer */ background-color: var(--sklearn-color-background); } /* Toggleable label */ #sk-container-id-1 label.sk-toggleable__label { cursor: pointer; display: flex; width: 100%; margin-bottom: 0; padding: 0.5em; box-sizing: border-box; text-align: center; align-items: start; justify-content: space-between; gap: 0.5em; } #sk-container-id-1 label.sk-toggleable__label .caption { font-size: 0.6rem; font-weight: lighter; color: var(--sklearn-color-text-muted); } #sk-container-id-1 label.sk-toggleable__label-arrow:before { /* Arrow on the left of the label */ content: \"▸\"; float: left; margin-right: 0.25em; color: var(--sklearn-color-icon); } #sk-container-id-1 label.sk-toggleable__label-arrow:hover:before { color: var(--sklearn-color-text); } /* Toggleable content - dropdown */ #sk-container-id-1 div.sk-toggleable__content { max-height: 0; max-width: 0; overflow: hidden; text-align: left; /* unfitted */ background-color: var(--sklearn-color-unfitted-level-0); } #sk-container-id-1 div.sk-toggleable__content.fitted { /* fitted */ background-color: var(--sklearn-color-fitted-level-0); } #sk-container-id-1 div.sk-toggleable__content pre { margin: 0.2em; border-radius: 0.25em; color: var(--sklearn-color-text); /* unfitted */ background-color: var(--sklearn-color-unfitted-level-0); } #sk-container-id-1 div.sk-toggleable__content.fitted pre { /* unfitted */ background-color: var(--sklearn-color-fitted-level-0); } #sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content { /* Expand drop-down */ max-height: 200px; max-width: 100%; overflow: auto; } #sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before { content: \"▾\"; } /* Pipeline/ColumnTransformer-specific style */ #sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label { color: var(--sklearn-color-text); background-color: var(--sklearn-color-unfitted-level-2); } #sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label { background-color: var(--sklearn-color-fitted-level-2); } /* Estimator-specific style */ /* Colorize estimator box */ #sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label { /* unfitted */ background-color: var(--sklearn-color-unfitted-level-2); } #sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label { /* fitted */ background-color: var(--sklearn-color-fitted-level-2); } #sk-container-id-1 div.sk-label label.sk-toggleable__label, #sk-container-id-1 div.sk-label label { /* The background is the default theme color */ color: var(--sklearn-color-text-on-default-background); } /* On hover, darken the color of the background */ #sk-container-id-1 div.sk-label:hover label.sk-toggleable__label { color: var(--sklearn-color-text); background-color: var(--sklearn-color-unfitted-level-2); } /* Label box, darken color on hover, fitted */ #sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted { color: var(--sklearn-color-text); background-color: var(--sklearn-color-fitted-level-2); } /* Estimator label */ #sk-container-id-1 div.sk-label label { font-family: monospace; font-weight: bold; display: inline-block; line-height: 1.2em; } #sk-container-id-1 div.sk-label-container { text-align: center; } /* Estimator-specific */ #sk-container-id-1 div.sk-estimator { font-family: monospace; border: 1px dotted var(--sklearn-color-border-box); border-radius: 0.25em; box-sizing: border-box; margin-bottom: 0.5em; /* unfitted */ background-color: var(--sklearn-color-unfitted-level-0); } #sk-container-id-1 div.sk-estimator.fitted { /* fitted */ background-color: var(--sklearn-color-fitted-level-0); } /* on hover */ #sk-container-id-1 div.sk-estimator:hover { /* unfitted */ background-color: var(--sklearn-color-unfitted-level-2); } #sk-container-id-1 div.sk-estimator.fitted:hover { /* fitted */ background-color: var(--sklearn-color-fitted-level-2); } /* Specification for estimator info (e.g. \"i\" and \"?\") */ /* Common style for \"i\" and \"?\" */ .sk-estimator-doc-link, a:link.sk-estimator-doc-link, a:visited.sk-estimator-doc-link { float: right; font-size: smaller; line-height: 1em; font-family: monospace; background-color: var(--sklearn-color-background); border-radius: 1em; height: 1em; width: 1em; text-decoration: none !important; margin-left: 0.5em; text-align: center; /* unfitted */ border: var(--sklearn-color-unfitted-level-1) 1pt solid; color: var(--sklearn-color-unfitted-level-1); } .sk-estimator-doc-link.fitted, a:link.sk-estimator-doc-link.fitted, a:visited.sk-estimator-doc-link.fitted { /* fitted */ border: var(--sklearn-color-fitted-level-1) 1pt solid; color: var(--sklearn-color-fitted-level-1); } /* On hover */ div.sk-estimator:hover .sk-estimator-doc-link:hover, .sk-estimator-doc-link:hover, div.sk-label-container:hover .sk-estimator-doc-link:hover, .sk-estimator-doc-link:hover { /* unfitted */ background-color: var(--sklearn-color-unfitted-level-3); color: var(--sklearn-color-background); text-decoration: none; } div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover, .sk-estimator-doc-link.fitted:hover, div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover, .sk-estimator-doc-link.fitted:hover { /* fitted */ background-color: var(--sklearn-color-fitted-level-3); color: var(--sklearn-color-background); text-decoration: none; } /* Span, style for the box shown on hovering the info icon */ .sk-estimator-doc-link span { display: none; z-index: 9999; position: relative; font-weight: normal; right: .2ex; padding: .5ex; margin: .5ex; width: min-content; min-width: 20ex; max-width: 50ex; color: var(--sklearn-color-text); box-shadow: 2pt 2pt 4pt #999; /* unfitted */ background: var(--sklearn-color-unfitted-level-0); border: .5pt solid var(--sklearn-color-unfitted-level-3); } .sk-estimator-doc-link.fitted span { /* fitted */ background: var(--sklearn-color-fitted-level-0); border: var(--sklearn-color-fitted-level-3); } .sk-estimator-doc-link:hover span { display: block; } /* \"?\"-specific style due to the `` HTML tag */ #sk-container-id-1 a.estimator_doc_link { float: right; font-size: 1rem; line-height: 1em; font-family: monospace; background-color: var(--sklearn-color-background); border-radius: 1rem; height: 1rem; width: 1rem; text-decoration: none; /* unfitted */ color: var(--sklearn-color-unfitted-level-1); border: var(--sklearn-color-unfitted-level-1) 1pt solid; } #sk-container-id-1 a.estimator_doc_link.fitted { /* fitted */ border: var(--sklearn-color-fitted-level-1) 1pt solid; color: var(--sklearn-color-fitted-level-1); } /* On hover */ #sk-container-id-1 a.estimator_doc_link:hover { /* unfitted */ background-color: var(--sklearn-color-unfitted-level-3); color: var(--sklearn-color-background); text-decoration: none; } #sk-container-id-1 a.estimator_doc_link.fitted:hover { /* fitted */ background-color: var(--sklearn-color-fitted-level-3); } KMeans(n_clusters=19, random_state=22)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.KMeans?Documentation for KMeansiFittedKMeans(n_clusters=19, random_state=22) # Plot the elbow curve plt.figure(figsize=(8, 6)) plt.plot(cluster_range, inertia_values, marker=&#39;o&#39;, linestyle=&#39;-&#39;, color=&#39;b&#39;) plt.title(&#39;Elbow Method for Optimal Number of Clusters&#39;) plt.xlabel(&#39;Number of Clusters&#39;) plt.ylabel(&#39;Inertia&#39;) plt.grid(True) plt.show() Looking at the elbow plot, the optimal number of clusters moving forward is 10. Now lets run the k-means algorithm with 10 clusters and put the cluster labels back onto the original data frame. # Run K-means with 10 clusters kmeans = KMeans(n_clusters=10, random_state=22) kmeans.fit(pca_results) # Use the PCA results for clustering #sk-container-id-2 { /* Definition of color scheme common for light and dark mode */ --sklearn-color-text: #000; --sklearn-color-text-muted: #666; --sklearn-color-line: gray; /* Definition of color scheme for unfitted estimators */ --sklearn-color-unfitted-level-0: #fff5e6; --sklearn-color-unfitted-level-1: #f6e4d2; --sklearn-color-unfitted-level-2: #ffe0b3; --sklearn-color-unfitted-level-3: chocolate; /* Definition of color scheme for fitted estimators */ --sklearn-color-fitted-level-0: #f0f8ff; --sklearn-color-fitted-level-1: #d4ebff; --sklearn-color-fitted-level-2: #b3dbfd; --sklearn-color-fitted-level-3: cornflowerblue; /* Specific color for light theme */ --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black))); --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white))); --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black))); --sklearn-color-icon: #696969; @media (prefers-color-scheme: dark) { /* Redefinition of color scheme for dark theme */ --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white))); --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111))); --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white))); --sklearn-color-icon: #878787; } } #sk-container-id-2 { color: var(--sklearn-color-text); } #sk-container-id-2 pre { padding: 0; } #sk-container-id-2 input.sk-hidden--visually { border: 0; clip: rect(1px 1px 1px 1px); clip: rect(1px, 1px, 1px, 1px); height: 1px; margin: -1px; overflow: hidden; padding: 0; position: absolute; width: 1px; } #sk-container-id-2 div.sk-dashed-wrapped { border: 1px dashed var(--sklearn-color-line); margin: 0 0.4em 0.5em 0.4em; box-sizing: border-box; padding-bottom: 0.4em; background-color: var(--sklearn-color-background); } #sk-container-id-2 div.sk-container { /* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */ display: inline-block !important; position: relative; } #sk-container-id-2 div.sk-text-repr-fallback { display: none; } div.sk-parallel-item, div.sk-serial, div.sk-item { /* draw centered vertical line to link estimators */ background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background)); background-size: 2px 100%; background-repeat: no-repeat; background-position: center center; } /* Parallel-specific style estimator block */ #sk-container-id-2 div.sk-parallel-item::after { content: \"\"; width: 100%; border-bottom: 2px solid var(--sklearn-color-text-on-default-background); flex-grow: 1; } #sk-container-id-2 div.sk-parallel { display: flex; align-items: stretch; justify-content: center; background-color: var(--sklearn-color-background); position: relative; } #sk-container-id-2 div.sk-parallel-item { display: flex; flex-direction: column; } #sk-container-id-2 div.sk-parallel-item:first-child::after { align-self: flex-end; width: 50%; } #sk-container-id-2 div.sk-parallel-item:last-child::after { align-self: flex-start; width: 50%; } #sk-container-id-2 div.sk-parallel-item:only-child::after { width: 0; } /* Serial-specific style estimator block */ #sk-container-id-2 div.sk-serial { display: flex; flex-direction: column; align-items: center; background-color: var(--sklearn-color-background); padding-right: 1em; padding-left: 1em; } /* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is clickable and can be expanded/collapsed. - Pipeline and ColumnTransformer use this feature and define the default style - Estimators will overwrite some part of the style using the `sk-estimator` class */ /* Pipeline and ColumnTransformer style (default) */ #sk-container-id-2 div.sk-toggleable { /* Default theme specific background. It is overwritten whether we have a specific estimator or a Pipeline/ColumnTransformer */ background-color: var(--sklearn-color-background); } /* Toggleable label */ #sk-container-id-2 label.sk-toggleable__label { cursor: pointer; display: flex; width: 100%; margin-bottom: 0; padding: 0.5em; box-sizing: border-box; text-align: center; align-items: start; justify-content: space-between; gap: 0.5em; } #sk-container-id-2 label.sk-toggleable__label .caption { font-size: 0.6rem; font-weight: lighter; color: var(--sklearn-color-text-muted); } #sk-container-id-2 label.sk-toggleable__label-arrow:before { /* Arrow on the left of the label */ content: \"▸\"; float: left; margin-right: 0.25em; color: var(--sklearn-color-icon); } #sk-container-id-2 label.sk-toggleable__label-arrow:hover:before { color: var(--sklearn-color-text); } /* Toggleable content - dropdown */ #sk-container-id-2 div.sk-toggleable__content { max-height: 0; max-width: 0; overflow: hidden; text-align: left; /* unfitted */ background-color: var(--sklearn-color-unfitted-level-0); } #sk-container-id-2 div.sk-toggleable__content.fitted { /* fitted */ background-color: var(--sklearn-color-fitted-level-0); } #sk-container-id-2 div.sk-toggleable__content pre { margin: 0.2em; border-radius: 0.25em; color: var(--sklearn-color-text); /* unfitted */ background-color: var(--sklearn-color-unfitted-level-0); } #sk-container-id-2 div.sk-toggleable__content.fitted pre { /* unfitted */ background-color: var(--sklearn-color-fitted-level-0); } #sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content { /* Expand drop-down */ max-height: 200px; max-width: 100%; overflow: auto; } #sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before { content: \"▾\"; } /* Pipeline/ColumnTransformer-specific style */ #sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label { color: var(--sklearn-color-text); background-color: var(--sklearn-color-unfitted-level-2); } #sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label { background-color: var(--sklearn-color-fitted-level-2); } /* Estimator-specific style */ /* Colorize estimator box */ #sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label { /* unfitted */ background-color: var(--sklearn-color-unfitted-level-2); } #sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label { /* fitted */ background-color: var(--sklearn-color-fitted-level-2); } #sk-container-id-2 div.sk-label label.sk-toggleable__label, #sk-container-id-2 div.sk-label label { /* The background is the default theme color */ color: var(--sklearn-color-text-on-default-background); } /* On hover, darken the color of the background */ #sk-container-id-2 div.sk-label:hover label.sk-toggleable__label { color: var(--sklearn-color-text); background-color: var(--sklearn-color-unfitted-level-2); } /* Label box, darken color on hover, fitted */ #sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted { color: var(--sklearn-color-text); background-color: var(--sklearn-color-fitted-level-2); } /* Estimator label */ #sk-container-id-2 div.sk-label label { font-family: monospace; font-weight: bold; display: inline-block; line-height: 1.2em; } #sk-container-id-2 div.sk-label-container { text-align: center; } /* Estimator-specific */ #sk-container-id-2 div.sk-estimator { font-family: monospace; border: 1px dotted var(--sklearn-color-border-box); border-radius: 0.25em; box-sizing: border-box; margin-bottom: 0.5em; /* unfitted */ background-color: var(--sklearn-color-unfitted-level-0); } #sk-container-id-2 div.sk-estimator.fitted { /* fitted */ background-color: var(--sklearn-color-fitted-level-0); } /* on hover */ #sk-container-id-2 div.sk-estimator:hover { /* unfitted */ background-color: var(--sklearn-color-unfitted-level-2); } #sk-container-id-2 div.sk-estimator.fitted:hover { /* fitted */ background-color: var(--sklearn-color-fitted-level-2); } /* Specification for estimator info (e.g. \"i\" and \"?\") */ /* Common style for \"i\" and \"?\" */ .sk-estimator-doc-link, a:link.sk-estimator-doc-link, a:visited.sk-estimator-doc-link { float: right; font-size: smaller; line-height: 1em; font-family: monospace; background-color: var(--sklearn-color-background); border-radius: 1em; height: 1em; width: 1em; text-decoration: none !important; margin-left: 0.5em; text-align: center; /* unfitted */ border: var(--sklearn-color-unfitted-level-1) 1pt solid; color: var(--sklearn-color-unfitted-level-1); } .sk-estimator-doc-link.fitted, a:link.sk-estimator-doc-link.fitted, a:visited.sk-estimator-doc-link.fitted { /* fitted */ border: var(--sklearn-color-fitted-level-1) 1pt solid; color: var(--sklearn-color-fitted-level-1); } /* On hover */ div.sk-estimator:hover .sk-estimator-doc-link:hover, .sk-estimator-doc-link:hover, div.sk-label-container:hover .sk-estimator-doc-link:hover, .sk-estimator-doc-link:hover { /* unfitted */ background-color: var(--sklearn-color-unfitted-level-3); color: var(--sklearn-color-background); text-decoration: none; } div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover, .sk-estimator-doc-link.fitted:hover, div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover, .sk-estimator-doc-link.fitted:hover { /* fitted */ background-color: var(--sklearn-color-fitted-level-3); color: var(--sklearn-color-background); text-decoration: none; } /* Span, style for the box shown on hovering the info icon */ .sk-estimator-doc-link span { display: none; z-index: 9999; position: relative; font-weight: normal; right: .2ex; padding: .5ex; margin: .5ex; width: min-content; min-width: 20ex; max-width: 50ex; color: var(--sklearn-color-text); box-shadow: 2pt 2pt 4pt #999; /* unfitted */ background: var(--sklearn-color-unfitted-level-0); border: .5pt solid var(--sklearn-color-unfitted-level-3); } .sk-estimator-doc-link.fitted span { /* fitted */ background: var(--sklearn-color-fitted-level-0); border: var(--sklearn-color-fitted-level-3); } .sk-estimator-doc-link:hover span { display: block; } /* \"?\"-specific style due to the `` HTML tag */ #sk-container-id-2 a.estimator_doc_link { float: right; font-size: 1rem; line-height: 1em; font-family: monospace; background-color: var(--sklearn-color-background); border-radius: 1rem; height: 1rem; width: 1rem; text-decoration: none; /* unfitted */ color: var(--sklearn-color-unfitted-level-1); border: var(--sklearn-color-unfitted-level-1) 1pt solid; } #sk-container-id-2 a.estimator_doc_link.fitted { /* fitted */ border: var(--sklearn-color-fitted-level-1) 1pt solid; color: var(--sklearn-color-fitted-level-1); } /* On hover */ #sk-container-id-2 a.estimator_doc_link:hover { /* unfitted */ background-color: var(--sklearn-color-unfitted-level-3); color: var(--sklearn-color-background); text-decoration: none; } #sk-container-id-2 a.estimator_doc_link.fitted:hover { /* fitted */ background-color: var(--sklearn-color-fitted-level-3); } KMeans(n_clusters=10, random_state=22)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.KMeans?Documentation for KMeansiFittedKMeans(n_clusters=10, random_state=22) # Get the cluster labels for each data point cluster_labels = kmeans.labels_ pca_results[&quot;Cluster Labels&quot;] = cluster_labels #Add cluster labels back to the orignal data data[&quot;Cluster Labels&quot;] = cluster_labels data.to_csv(&#39;clustering_results.csv&#39;,index=False) "],["results.html", "4 Results", " 4 Results import pandas as pd data = pd.read_csv(r&quot;C:\\Project for IAA\\N1\\clustering_results.csv&quot;) Now we can look at the variables in the data to see what the different clusters look like. # Count how many unique counties are in each Cluster Label county_counts = data.groupby(&#39;Cluster Labels&#39;)[&#39;County&#39;].nunique() # Create a bar plot to visualize the counts of counties in each cluster plt.figure(figsize=(10, 6)) plt.bar(county_counts.index, county_counts.values, color=&#39;skyblue&#39;) plt.xticks(np.arange(0, 10), rotation=0) # Adjust as needed ## ([&lt;matplotlib.axis.XTick object at 0x000001BF93850E90&gt;, &lt;matplotlib.axis.XTick object at 0x000001BF93852C00&gt;, &lt;matplotlib.axis.XTick object at 0x000001BF969235F0&gt;, &lt;matplotlib.axis.XTick object at 0x000001BF938523C0&gt;, &lt;matplotlib.axis.XTick object at 0x000001BF9748E9F0&gt;, &lt;matplotlib.axis.XTick object at 0x000001BF9748F800&gt;, &lt;matplotlib.axis.XTick object at 0x000001BF9748D460&gt;, &lt;matplotlib.axis.XTick object at 0x000001BF9748F6B0&gt;, &lt;matplotlib.axis.XTick object at 0x000001BF90795D90&gt;, &lt;matplotlib.axis.XTick object at 0x000001BF938726C0&gt;], [Text(0, 0, &#39;0&#39;), Text(1, 0, &#39;1&#39;), Text(2, 0, &#39;2&#39;), Text(3, 0, &#39;3&#39;), Text(4, 0, &#39;4&#39;), Text(5, 0, &#39;5&#39;), Text(6, 0, &#39;6&#39;), Text(7, 0, &#39;7&#39;), Text(8, 0, &#39;8&#39;), Text(9, 0, &#39;9&#39;)]) # Title and labels plt.title(&#39;Count of Counties by Cluster Groups&#39;) plt.xlabel(&#39;Cluster Group Labels&#39;) plt.ylabel(&#39;Number of Unique Counties&#39;) # Show the plot plt.show() Here we see a raw count for how many counties are in each cluster group. The majority of the counties are in cluster 6. This can be expected due to the counties being tightly packed when we did our cluster analysis. #These two counties have seen huge increases in low access to stores. Since this #would be a place recommended for N1 to deploy its resources, I subset the #daa to exclude them from the data. This will even out the skewness in a #couple of the bar charts making it easier on the eyes. data = data[~((data[&#39;State&#39;] == &#39;IL&#39;) &amp; (data[&#39;County&#39;] == &#39;Putnam&#39;))] data = data[~((data[&#39;State&#39;] == &#39;TX&#39;) &amp; (data[&#39;County&#39;] == &#39;Stonewall&#39;))] float_columns = data.select_dtypes(include=[&#39;float64&#39;]).columns # Loop through each &#39;float64&#39; column in &#39;data&#39; for column in float_columns: plt.figure(figsize=(10, 6)) # For each cluster, calculate the median of the variable cluster_medians = data.groupby(&#39;Cluster Labels&#39;)[column].median() # Create a bar plot for the column, grouped by &#39;Cluster Labels&#39; plt.bar(cluster_medians.index, cluster_medians.values, color=&#39;lightcoral&#39;) plt.xticks(np.arange(0, 10), rotation=0) # Adjust as needed # Title and labels plt.title(f&#39;Median {column} by Cluster Labels&#39;) plt.xlabel(&#39;Cluster Labels&#39;) plt.ylabel(f&#39;Median {column}&#39;) # Show the plot plt.show() From these graphs, there are a few key insights that should be recognized: 1. In the PCH_LACCESS_POP_10_15 graph, there is a huge increase in the percentage of the population that have low access to stores in the second group of counties. After some digging, there are 5 counties in this group. 4 of them are in Hawaii and the other one is in Alaska. If N1 has the resources, these 5 counties would be great candidates for N1 to help with food access challenges. The second insight from this graph is the increase in group 8. This is a smaller group of counties that are seeing an increase in the percentage of the population that is struggling to get food access. These counties are also ideal candidates for N1 to utilize its resources to aid in people getting better access to food. Utilizing the graph that shows the distribution of the Black population across the groups, we see that the majority of this group is within the counties in group 8. If N1 uses it resources to help these communities with increasing access to food, they should expect the majority of these populations to be Black. This knowledge will help N1 tailor their programs to these communities. In the PCH_LACCESS_HHNV_10_15 graph, we see group 9 has the biggest percentage of people that have low access to food and don’t have access to a car. This is vital information if N1 decides to deploy its resources to these communities. When creating a program to increase the access to food, N1 should consider having a option where they help deliver food to households or setting up food pantries within walking distances in these communities to give them better access to food. Looking into the White, Hispanic, and Multiracial graphs, we see see these ethnic groups strongly represent group 9. If N1 decides to deploy resources to help these communities, they should expect these populations to be White, Hispanic, or Multiracial. Lastly, I am going to recreate the graphs I mentioned above to get them looking nicer and presentation quality. PCH_LACESS_HHNV_10_15 Plot # Plot for PCH_LACCESS_HHNV_10_15 plt.figure(figsize=(10, 6)) # Calculate the median for each cluster cluster_medians = data.groupby(&#39;Cluster Labels&#39;)[&#39;PCH_LACCESS_HHNV_10_15&#39;].median() # Define color list: grey for bars 1-8, sky blue for bar 9 colors = [&#39;grey&#39; if i != 9 else &#39;skyblue&#39; for i in cluster_medians.index] # Create the bar plot with the color list plt.bar(cluster_medians.index, cluster_medians.values, color=colors) # Customize the x-ticks and rotation plt.xticks(np.arange(0, 10), rotation=0) # Adjust as needed ## ([&lt;matplotlib.axis.XTick object at 0x000001BFC6EB0EF0&gt;, &lt;matplotlib.axis.XTick object at 0x000001BF97BE3830&gt;, &lt;matplotlib.axis.XTick object at 0x000001BFC6F62750&gt;, &lt;matplotlib.axis.XTick object at 0x000001BFC6F61C40&gt;, &lt;matplotlib.axis.XTick object at 0x000001BFC6F61B80&gt;, &lt;matplotlib.axis.XTick object at 0x000001BFC6F62DB0&gt;, &lt;matplotlib.axis.XTick object at 0x000001BFC6F63D10&gt;, &lt;matplotlib.axis.XTick object at 0x000001BFC6F7C7A0&gt;, &lt;matplotlib.axis.XTick object at 0x000001BFC6F63C50&gt;, &lt;matplotlib.axis.XTick object at 0x000001BF97C16B40&gt;], [Text(0, 0, &#39;0&#39;), Text(1, 0, &#39;1&#39;), Text(2, 0, &#39;2&#39;), Text(3, 0, &#39;3&#39;), Text(4, 0, &#39;4&#39;), Text(5, 0, &#39;5&#39;), Text(6, 0, &#39;6&#39;), Text(7, 0, &#39;7&#39;), Text(8, 0, &#39;8&#39;), Text(9, 0, &#39;9&#39;)]) # Title and labels plt.title(&#39;Median 2010 to 2015 People with Low Access and No Car&#39;) plt.xlabel(&#39;Group Label&#39;) plt.ylabel(&#39;% Change&#39;) # Show the plot plt.show() plt.clf() PCH_LACCESS_POP_10_15 Plot # Plot for PCH_LACESS_HHNV_10_15 plt.figure(figsize=(10, 6)) # Calculate the median for each cluster cluster_medians = data.groupby(&#39;Cluster Labels&#39;)[&#39;PCH_LACCESS_POP_10_15&#39;].median() # Define color list: grey for bars 1-8, sky blue for bar 9 colors = [&#39;grey&#39; if i != 8 else &#39;skyblue&#39; for i in cluster_medians.index] # Create the bar plot with the color list plt.bar(cluster_medians.index, cluster_medians.values, color=colors) # Add a horizontal black line at y=0 plt.axhline(y=0, color=&#39;black&#39;, linewidth=2) # Customize the x-ticks and rotation plt.xticks(np.arange(0, 10), rotation=0) # Adjust as needed ## ([&lt;matplotlib.axis.XTick object at 0x000001BF9265BA70&gt;, &lt;matplotlib.axis.XTick object at 0x000001BF9265A0F0&gt;, &lt;matplotlib.axis.XTick object at 0x000001BF9269DDC0&gt;, &lt;matplotlib.axis.XTick object at 0x000001BF90BCCE00&gt;, &lt;matplotlib.axis.XTick object at 0x000001BF90BDCB30&gt;, &lt;matplotlib.axis.XTick object at 0x000001BF90BDD490&gt;, &lt;matplotlib.axis.XTick object at 0x000001BF90BDCEC0&gt;, &lt;matplotlib.axis.XTick object at 0x000001BF97B88AD0&gt;, &lt;matplotlib.axis.XTick object at 0x000001BFB3605B20&gt;, &lt;matplotlib.axis.XTick object at 0x000001BFB36053D0&gt;], [Text(0, 0, &#39;0&#39;), Text(1, 0, &#39;1&#39;), Text(2, 0, &#39;2&#39;), Text(3, 0, &#39;3&#39;), Text(4, 0, &#39;4&#39;), Text(5, 0, &#39;5&#39;), Text(6, 0, &#39;6&#39;), Text(7, 0, &#39;7&#39;), Text(8, 0, &#39;8&#39;), Text(9, 0, &#39;9&#39;)]) # Title and labels plt.title(&#39;Median 2010 to 2015 Population with Low Access to Stores&#39;) plt.xlabel(&#39;Group Label&#39;) plt.ylabel(&#39;% Change&#39;) # Show the plot plt.show() plt.clf() I am going to save the data so I can upload it into Tableau. data.to_csv(&#39;data_tableau.csv&#39;,index=False) "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
